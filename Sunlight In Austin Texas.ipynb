{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0"
      },
      "cell_type": "markdown",
      "source": "### This case study observes weather data from two sources from 1989 to 2010 of Austin, Texas. Climate measurments for each hour of the day, averaged for over 30 years."
    },
    {
      "metadata": {
        "_uuid": "d3a94d7b6446beb64cff35b2e6d9305153530fd5",
        "_cell_guid": "af71ee2f-8aab-40fe-8778-ec43c817d80c"
      },
      "cell_type": "markdown",
      "source": "## Loading the Data "
    },
    {
      "metadata": {
        "_uuid": "0710968f545f419000469d46c5ffe6d2dac6cd8c",
        "_cell_guid": "20e13b47-46bc-45d6-80dc-c5bf981082c8",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Import pandas\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom IPython.core.display import display, HTML\n\ndf = pd.read_csv(\"../input/noaa-qclcd-2011/2011_Austin_Weather.txt\")\ndf.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9677ccdd8993b4cccf9677285c227982789b3a6d",
        "_cell_guid": "d0ed41e3-af66-4f1d-82f8-801a044dbc23"
      },
      "cell_type": "markdown",
      "source": "* We read the file into a DataFrame using the default arguments. \n* After inspecting it, we see that there is no header, and thus the columns have no labels. There is also no obvious index column, since none of the data columns contain a full date or time. \n* We re-read the file specifying that there are no headers supplied. "
    },
    {
      "metadata": {
        "_uuid": "4b49d71d7e6ba078ecd4cdf066f69fa207debbf7",
        "_cell_guid": "9c79e151-a809-42e7-8626-3f62aa6c007b",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Read the 2011_Austin_Weather.txt as a DataFrame attributing no header\ndf = pd.read_csv('../input/noaa-qclcd-2011/2011_Austin_Weather.txt', header=None)\ndf.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4b38a41615c343e11cec21f44b91b05dd5637f4b",
        "_cell_guid": "4f401707-ecca-48cb-8685-b9ae272ce058",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "with open('../input/column-label/column_labels.txt') as file:\n    column_labels = file.read()\n    \n# Split on the comma to create a list: column_labels_list    \n    column_labels_list = column_labels.split(',')\n                 \n# Assign the new column labels to the DataFrame: df.columns\n    df.columns = column_labels_list\n\ndf.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "63d09ee4f67e2907afeaaead6b6af27e5a326af3",
        "_cell_guid": "ab79ae54-c75b-4db0-932d-2e1eb8493fbe"
      },
      "cell_type": "markdown",
      "source": "### We drop a few columns with attributes that are irrelevant"
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "41d685e763a53c549e224ae6d2314eb14327efb2",
        "_cell_guid": "5493cf50-d05a-4b94-86d0-7b64dcb40e01",
        "trusted": false
      },
      "cell_type": "code",
      "source": "list_to_drop = ['sky_conditionFlag',\n 'visibilityFlag',\n 'wx_and_obst_to_vision',\n 'wx_and_obst_to_visionFlag',\n 'dry_bulb_farenFlag',\n 'dry_bulb_celFlag',\n 'wet_bulb_farenFlag',\n 'wet_bulb_celFlag',\n 'dew_point_farenFlag',\n 'dew_point_celFlag',\n 'relative_humidityFlag',\n 'wind_speedFlag',\n 'wind_directionFlag',\n 'value_for_wind_character',\n 'value_for_wind_characterFlag',\n 'station_pressureFlag',\n 'pressure_tendencyFlag',\n 'pressure_tendency',\n 'presschange',\n 'presschangeFlag',\n 'sea_level_pressureFlag',\n 'hourly_precip',\n 'hourly_precipFlag',\n 'altimeter',\n 'record_type',\n 'altimeterFlag',\n 'junk']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1dbce085fd5c9d824b0670de2f6ad0bafe46ed6b",
        "_cell_guid": "94525f51-914c-4993-bbed-163101819803",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Remove the appropriate columns: df_dropped\ndf_dropped = df.drop(list_to_drop, axis='columns')\n\n# output of df_dropped.head()\nprint(df_dropped.head())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "31ce118c91caf9902b953cf5a0c80c9eafe45e01",
        "_cell_guid": "8f2b4358-a914-4cb8-b3ad-5482f65e8662"
      },
      "cell_type": "markdown",
      "source": "### Constructing a Time Series Data"
    },
    {
      "metadata": {
        "_uuid": "d8fd8be4da078f12c3c26af6c90a988dcde67b40",
        "_cell_guid": "5ad67ae8-a43e-42da-9c3d-d73c009a8941"
      },
      "cell_type": "markdown",
      "source": "We clean up the date and Time columns and combine them into a datetime collection to be used as the Index\n* First, we convert the 'date' column to a string with .astype(str) and assign to df_dropped['date']\n* Convert the date_string Series to datetime values with pd.to_datetime(). and using df.set_index() to create new time_series index"
    },
    {
      "metadata": {
        "_uuid": "ed6459018c1462a70b7da5d9009c1a0180198578",
        "_cell_guid": "a997d229-c060-4ab2-9b67-4e11e0127ea1",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Convert the date column to string: df_dropped['date']\ndf_dropped['date'] = df_dropped.date.astype(str)\n# Pad leading zeros to the Time column: df_dropped['Time']\ndf_dropped['Time'] = df_dropped['Time'].apply(lambda x:'{:0>4}'.format(x))\n\n# Concatenate the new date and Time columns\ndate_string = df_dropped['date']+df_dropped['Time']\n\n# Convert the date_string Series to datetime: date_times\ndate_times = pd.to_datetime(date_string, format='%Y%m%d%H%M')\n\n# Set the index to be the new date_times container: df_clean\ndf_clean = df_dropped.set_index(date_times)\n\n# Print the output of df_clean.head()\ndf_clean.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bac9e79c737f9c184b0f4e59306fc14168d437ea",
        "_cell_guid": "33ca8250-2765-47d2-8ebc-9248a92852b9"
      },
      "cell_type": "markdown",
      "source": "### Filling in Missing Values "
    },
    {
      "metadata": {
        "_uuid": "ec3b7fab636d1b35c52898c84dd4bc3d51b256e0",
        "_cell_guid": "2c53b569-ac23-45d4-a6ca-406442d661d5",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df_clean.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e26e91e021d8f4570209c4582e3cca2e5b7335d3",
        "_cell_guid": "5d526879-d901-4e19-b74f-fe2c10be0c53"
      },
      "cell_type": "markdown",
      "source": "###  Checking and specifying missing values ussing parameter errors='coerce' "
    },
    {
      "metadata": {
        "_uuid": "c2b75010ddc3f714f95090ef462c88a80c7461cf",
        "_cell_guid": "2743e99f-b378-45ed-8585-0110443aecde",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Print the dry_bulb_faren temperature between 8 AM and 9 AM on June 20, 2011\nprint(df_clean.loc['2011-06-20 8:00':'2011-06-20 9:00', 'dry_bulb_faren'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "774b8cb92bea3c973f6c5f2d10d0bc1adf5cafe8",
        "_cell_guid": "fb2f3daf-ac6e-435d-bf2d-4e480885b67d"
      },
      "cell_type": "markdown",
      "source": "> * The numeric columns contain missing values labeled as 'M' \n* We're going to solve both, missing values and type convertion by using pd.to_numeric()\n* We use errors='coerce'  because  whenever a convertion error happens, such as string to float, the values is converted to a NaN, representing a missing value.\n* We convert dry_bulb_faren, wind_speed, and dew_point_faren"
    },
    {
      "metadata": {
        "_uuid": "2cc6bd9dd0f4fabbdf030769a7fdacac2975ea2e",
        "_cell_guid": "bff8e7c7-4ee3-40a9-8076-80fdb1dd2ede",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Convert the dry_bulb_faren column to numeric values: df_clean['dry_bulb_faren']\ndf_clean['dry_bulb_faren'] = pd.to_numeric(df_clean['dry_bulb_faren'], errors='coerce')\n\n# Print the transformed dry_bulb_faren temperature between 8 AM and 9 AM on June 20, 2011\nprint(df_clean.loc['2011-06-20 8:00':'2011-06-20 9:00', 'dry_bulb_faren'])\n\n# Convert the wind_speed and dew_point_faren columns to numeric values\ndf_clean['wind_speed'] = pd.to_numeric(df_clean['wind_speed'], errors='coerce')\ndf_clean['dew_point_faren'] = pd.to_numeric(df_clean['dew_point_faren'], errors='coerce')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ac7d1cce1952e7205502a8ab6a0085507538de13",
        "_cell_guid": "378fc1e3-75e1-46c5-83bc-d04ed1b3311e"
      },
      "cell_type": "markdown",
      "source": "### Statistical EDA"
    },
    {
      "metadata": {
        "_uuid": "8f9d42b47dd6650e0e8e4b660bff459f2cd6d9e9",
        "_cell_guid": "ba7f047b-5bac-4715-97f9-d397a08e7876"
      },
      "cell_type": "markdown",
      "source": "* Partial DateTime selection"
    },
    {
      "metadata": {
        "_uuid": "422bce34794f9bb3ecfe24ba10dd0116b8b71945",
        "_cell_guid": "dfa8d124-191e-46d6-a196-701e744e0700",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Print the median of the dry_bulb_faren column\nprint(df_clean.dry_bulb_faren.median())\n\n# Print the median of the dry_bulb_faren column for the time range '2011-Apr':'2011-Jun'\nprint(df_clean.loc['2011-Apr':'2011-Jun', 'dry_bulb_faren'].median())\n\n# Print the median of the dry_bulb_faren column for the month of January\nprint(df_clean.loc['2011-Jan', 'dry_bulb_faren'].median())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "94ee14adca0026e21f39f4d0c51047f9f215646f",
        "_cell_guid": "cc7b04d7-4b75-4db7-8db5-c54b72ba1ac2"
      },
      "cell_type": "markdown",
      "source": "> * We now compare the 2011 weather data with the 30-year normals reported in 2010. We find outm how much hotter was every day in 2011 than expected from the 30-year averag\n* Downsample df_clean with daily frequency and aggregate by the mean. \n* Extract the dry_bulb_faren column from daily_mean_2011\n* We see that the indexes of df_clean and df_climate are not aligned - df_clean has dates in 2011, while df_climate has dates in 2010. We make use of of *.reset_index()* method to make sure the Series align properly."
    },
    {
      "metadata": {
        "_uuid": "cfddce1e275f7aeee352b28913f858ada8313e7e",
        "_cell_guid": "61b5a6b0-ffdc-4d3b-b976-fb4e974af1db"
      },
      "cell_type": "markdown",
      "source": "#### Compute Daily Frequency Average "
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "89a5ddcd739f7d5c8f79799e13733d9767503799",
        "_cell_guid": "94b7ace3-04f5-419d-bf06-e15186c3c54b",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Read the file from input\ndf_climate_2010 = pd.read_csv('../input/weather_data_austin_2010/weather_data_austin_2010.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4470b4e935cab1a53c88b930e8d0533c1bb85fa0",
        "_cell_guid": "a4d43ef1-1117-4da3-9e09-861d767fe31e"
      },
      "cell_type": "markdown",
      "source": "### We downsample the index from hourly to daily based"
    },
    {
      "metadata": {
        "_uuid": "1ee239fa50c84e585b8df65ea6688df8ae15625f",
        "_cell_guid": "ae470358-b4d1-4926-824d-94d6290f5fd3"
      },
      "cell_type": "markdown",
      "source": "We prepare the data from 2010-austin-weather data set. \n* First we convert it to time-series format"
    },
    {
      "metadata": {
        "_uuid": "cf577fcd70a4e17f3a112263e66e127ae3760027",
        "_cell_guid": "e69ab115-1957-4062-bb6b-ad484f632b29",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#print(df_climate_2010)\n# set.index() to df_climate_2010 for time series \ndf_climate_2010.Date = pd.to_datetime(df_climate_2010.Date)\ndf_climate_2010.set_index(df_climate_2010.Date, inplace=True)\ndf_climate_2010_copy = df_climate_2010.copy()\ndf_climate_2010.head(2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "cd1cfce2458a88c885428a1c383045552b2ffbe0",
        "_cell_guid": "9338eb85-193b-49f4-9c00-958e3b53641d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Downsample df_clean by day and aggregate by mean: daily_mean_2011\ndaily_mean_2011 = df_clean.resample('D').mean()\n\n# Extract the dry_bulb_faren column from daily_mean_2011 using .values: daily_temp_2011\ndaily_temp_2011 = daily_mean_2011['dry_bulb_faren'].values\n\n# Downsample df_climate by day and aggregate by mean: daily_climate\ndaily_climate_2010 = df_climate_2010.resample('D').mean()\n\n# Extract the Temperature column from daily_climate using .reset_index(): daily_temp_climate\ndaily_temp_climate = daily_climate_2010.reset_index()['Temperature']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e399d419da1485b01490a9cb78f99fdcd2d392ed",
        "_cell_guid": "0938de2a-3463-4352-b71c-b9af346d90a7"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "_uuid": "5cb5010089bc6d1d316a166375d4df8f18bdb9c8",
        "_cell_guid": "e0ce2dcb-8396-4fb4-bfd3-f48109346322"
      },
      "cell_type": "markdown",
      "source": ">### We compare and see the difference in Temperatures between 2010 and 2011"
    },
    {
      "metadata": {
        "_uuid": "8f9de1677d98fce05d37b5ecf85464b05d14bf67",
        "_cell_guid": "f460c086-a395-446b-8c8e-ee3911ed83bc",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "\n# Compute the difference between the two arrays and print the mean difference\ndifference = daily_temp_2011 - daily_temp_climate\nprint(difference.mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3241408b3d3f1913c236c735404003958787b9be",
        "_cell_guid": "b3d4e3fa-f9ea-45c4-8097-1539893f203d"
      },
      "cell_type": "markdown",
      "source": "#### As computed above the average daily temperature was **1.33** higher between 2011 and 2010."
    },
    {
      "metadata": {
        "_uuid": "274ac441efe51c7f3f83d73f2c5f81485700b154",
        "_cell_guid": "aeceaaa0-1912-4c32-8199-89515e2144bc"
      },
      "cell_type": "markdown",
      "source": ">### On average, how much hotter is it when the sun is shining?"
    },
    {
      "metadata": {
        "_uuid": "014a85d99612fd7909734f0c99369cdad5778ee5",
        "_cell_guid": "1545b279-5c88-42c9-9f95-2a477dbcacf1"
      },
      "cell_type": "markdown",
      "source": " We get this information with  'sky_condition' which provides information about whether the day was sunny ('CLR') or overcast ('OVC')."
    },
    {
      "metadata": {
        "collapsed": true,
        "_uuid": "5cc252182c97846b89728aa6c193fc7b50e5ecd9",
        "_cell_guid": "2afb3207-e8a0-4bc8-bd33-9f104bd40fdd",
        "trusted": false
      },
      "cell_type": "code",
      "source": "#print(df_clean)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "deac83bfcac7ab0ec21461e5dea063e3924fde6f",
        "_cell_guid": "acfe560e-81bb-44b8-83ff-544d52037352",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Select days that are sunny: sunny\nsunny = df_clean.loc[df_clean['sky_condition'].str.contains('CLR')]\n\n# Select days that are overcast: overcast\novercast = df_clean.loc[df_clean['sky_condition'].str.contains('OVC')]\n\n# Resample sunny and overcast, aggregating by maximum daily temperature\nsunny_daily_max = sunny.resample('D').max()\novercast_daily_max = overcast.resample('D').max()\n\n# Print the difference between the mean of sunny_daily_max and overcast_daily_max\nprint(sunny_daily_max.mean() - overcast_daily_max.mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "604748f057179544d8d16e2f8e6120c1fb535f51",
        "_cell_guid": "5b6e890d-0a5d-4714-8c3a-b798e0e40b59"
      },
      "cell_type": "markdown",
      "source": " * We see here that in 2011 sunny days were *6.5 * hotter than in 2010."
    },
    {
      "metadata": {
        "_uuid": "97499754e9e192adfc843848c053072cf67e2d9c",
        "_cell_guid": "dc8c5b49-9579-437a-8833-f90ec364c8f4"
      },
      "cell_type": "markdown",
      "source": "> **Is there a correlation between temperature and visibility?**"
    },
    {
      "metadata": {
        "_uuid": "0805b07d98a8765a624a7e6ea1e3b518c8044467",
        "_cell_guid": "0b6706d4-3910-4d96-b8a3-5c410eda350b"
      },
      "cell_type": "markdown",
      "source": " * We select the 'visibility' and 'dry_bulb_faren' columns and resample them by week and aggregate the mean\n * We use the Pearson correlation to compute the coefficient. The values close to 1 here would indicate that there is a strong correlation between temperature and visibility.\n * A value close to 1 here would indicate that there is a strong correlation between temperature and visibility."
    },
    {
      "metadata": {
        "_uuid": "3581b77fa740dcab8c0c4cbe8bcad04443940f3d",
        "_cell_guid": "c1dee14b-7af3-417c-80c1-ae5bba5587ba",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Select the visibility and dry_bulb_faren columns and resample them: weekly_mean\nvisibility_temperature=df_clean[['visibility', 'dry_bulb_faren']]\nweekly_mean = visibility_temperature.resample('W').mean()\n# Print the output of weekly_mean.corr()\nprint(weekly_mean.corr())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1fe58a2539bcce9efad5bd078ac38cf086b9c5b9",
        "_cell_guid": "b86f73bb-bbea-4b0c-8ce9-48afc0200aaf"
      },
      "cell_type": "markdown",
      "source": "**We are not able to see the visibilty column. Let us look into the column some more**"
    },
    {
      "metadata": {
        "_uuid": "9bac81e9e5505a52bc4ed266c2c9e4b598499724",
        "_cell_guid": "fc5f0a20-4449-4355-96ce-f0540842fc3f",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df_clean.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0194a862787d5220efc6f679c29ff044de04cb24",
        "_cell_guid": "5e033130-ab4f-479c-9457-fed3f2a80325"
      },
      "cell_type": "markdown",
      "source": "We convert the visibilty column from type object to numeric."
    },
    {
      "metadata": {
        "_uuid": "ea58a5b222932a3e467fe7f14cb2689a1995767e",
        "_cell_guid": "d1831b41-85d0-4f87-80d6-3b98bf2bd727",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df_clean['visibility'] = pd.to_numeric(df_clean['visibility'], errors='coerce')\nvisibility_temperature=df_clean[['visibility', 'dry_bulb_faren']]\nweekly_mean = visibility_temperature.resample('W').mean()\n# Print the output of weekly_mean.corr()\nprint(weekly_mean.corr())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ffd415d4b834fef1e6ef3193a0b4966b1d0db357",
        "_cell_guid": "8331eef2-9af2-4449-b9f8-e517ca7b2209"
      },
      "cell_type": "markdown",
      "source": "We see a medium correlation of **0.49**, a medium correlation. "
    },
    {
      "metadata": {
        "_uuid": "08dc3c0afb579703182d660ded50559657082048",
        "_cell_guid": "aa74a502-2563-4763-a5ea-77f93f3eaf69",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Plot weekly_mean with subplots=True\nweekly_mean.plot(subplots=True)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "829c679dc45fd6708b1fcaa5c2c3888c1652d661",
        "_cell_guid": "1f737cbc-ccaf-42bf-aefe-b84d57f27326"
      },
      "cell_type": "markdown",
      "source": "> ### Fraction of days that are sunny?"
    },
    {
      "metadata": {
        "_uuid": "f0745cbed3a3176f87ff4b6e148e379009740143",
        "_cell_guid": "3a340d63-bd69-47bf-9902-d5cc8f1ad01d",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#a Boolean Series for sunny days: sunny\nsunny = df_clean['sky_condition'] == 'CLR'\n# Resample the Boolean Series by day and compute the sum: sunny_hours\nsunny_hours = sunny.resample('D').sum()\n\n# Resample the Boolean Series by day and compute the count: total_hours\ntotal_hours = sunny.resample('D').count()\n\n# Divide sunny_hours by total_hours: sunny_fraction\nsunny_fraction = sunny_hours / total_hours\n\n# Make a box plot of sunny_fraction\nsunny_fraction.plot(kind='box')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "74904e1518b9e4752c903003fc9373030d8a63bf",
        "_cell_guid": "05fb6072-ed38-49a2-9496-62cca3ab559e"
      },
      "cell_type": "markdown",
      "source": "The median for sunny days is around **18%**.  75% of the values are under 40% of the sunny days."
    },
    {
      "metadata": {
        "_uuid": "c3d9a607ed4ce64babc398103ada4470072e99cf",
        "_cell_guid": "1f97fc99-f702-4793-a5ee-563bb6ec1df1"
      },
      "cell_type": "markdown",
      "source": "> ### What is the maximum temperature and dew point of each month?"
    },
    {
      "metadata": {
        "_uuid": "f4b59e16baea0db155f27b13d8aeb26c977f1c52",
        "_cell_guid": "232021b6-79b6-4fd6-8122-b94ffc092393"
      },
      "cell_type": "markdown",
      "source": "*  We  resample the 'dew_point_faren' and 'dry_bulb_faren' to get the maximum temperature and dew point in each month\n* Dew point is a measure of relative humidity based on pressure and temperature. A dew point above 65 is considered uncomfortable while a temperature above 90 is also considered uncomfortable.\n* We generate a histogram to get a better idea "
    },
    {
      "metadata": {
        "_uuid": "80947dfcf1543294f9dce1fe03e34656e308f037",
        "_cell_guid": "ca26352e-afac-477b-89b5-86ada0288edf",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Resample dew_point_faren and dry_bulb_faren by Month, aggregating the maximum values: monthly_max\nmonthly_max = df_clean[['dew_point_faren', 'dry_bulb_faren']].resample('M').max()\n\n# Generate a histogram with bins=8, alpha=0.5, subplots=True\nmonthly_max.plot(kind='hist', bins=8, alpha=0.5, subplots=True)\n\n# Show the plot\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3aebc714f171df8ac4cb87f2121932afd9d2ea77",
        "_cell_guid": "c464a71b-775b-4693-ac9e-f803cd5dd160"
      },
      "cell_type": "markdown",
      "source": "####  We see that the maximum dew point is above 65 every month "
    },
    {
      "metadata": {
        "_uuid": "d051ec6ff7485e9c48e26638383dca0c3845acbf",
        "_cell_guid": "a8da51b9-5938-483b-ad2a-7c889ffb42c9"
      },
      "cell_type": "markdown",
      "source": "> ### What is the Probability of high temperatures in 2011?"
    },
    {
      "metadata": {
        "_uuid": "540833f389a97e90c2d4b9d0542a1204d2aa9da1",
        "_cell_guid": "0e6b974e-cb17-4a62-a114-da7ccf06aa1a"
      },
      "cell_type": "markdown",
      "source": "* We compare the maximum temperature in August 2011 against that of the August 2010 climate normals. \n* We use a CDF plot to determine the probability of the 2011 daily maximum temperature in August being above the 2010 climate normal value.\n* We  select the maximum temperature in August in df_climate, and then maximum daily temperatures in August 2011. The days are then filtered out in August 2011 that were above the August 2010 maximum, and then used to construct a CDF plot. \n "
    },
    {
      "metadata": {
        "_uuid": "bd11da20b0b227ce57d82bbdc0ee88eac682ad1d",
        "_cell_guid": "a36c5c47-e8f5-48bb-9624-fc21fd123fd5",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Extract the maximum temperature in August 2010 from df_climate: august_max\naugust_max = df_climate_2010_copy.loc['2010-08', 'Temperature'].max()\nprint('Max temperature registered in August 2010 was ' + str(august_max.max()))\n\n# Resample the August 2011 temperatures in df_clean by day and aggregate the maximum value: august_2011\naugust_2011 = df_clean.loc['2011-Aug', 'dry_bulb_faren'].resample('D').max()\nprint('Max temperature registered in August 2011 was ' + str(august_2011.max()))\n\n# Filter out days in august_2011 where the value exceeded august_max: august_2011_high\naugust_2011_high = august_2011.loc[august_2011 > august_max]\n\n\n# Construct a CDF of august_2011_high\naugust_2011_high.plot(kind='hist', normed=True,cumulative=True, bins=25, linestyle='-', title='Probability of hotter day in August 2011')\nplt.xlabel('Registered Temperature')\n\n# Display the plot\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6463028de9cddb1173485f327f706100485db55f",
        "_cell_guid": "00945560-529b-4c28-896b-cb60bc8cae81"
      },
      "cell_type": "markdown",
      "source": "###  It shows that there was a 50% probability of the 2011 daily maximum temperature in August being 5 degrees above the 2010 climate normal value!"
    },
    {
      "metadata": {
        "_uuid": "fc975343dcbc06e2e2361e8d065be44fa5f56124",
        "_cell_guid": "105e5d5b-e262-4d64-84a6-98338c10c10b"
      },
      "cell_type": "markdown",
      "source": "## Conclusion"
    },
    {
      "metadata": {
        "_uuid": "aaccff4f548a72967f993b0ab08b7785f7545b75",
        "_cell_guid": "60c3dd43-9840-4933-9cf0-3dd2384d852c"
      },
      "cell_type": "markdown",
      "source": "  ** This dataset is my approach to using the Time Series Capabilites offered by Pandas.  \n     With the help of <a href=\"https://campus.datacamp.com/courses/pandas-foundations/\">Datacamp's</a> Pandas Foundation course, \n     I was able to  perform statistical and visual EDA  in pandas. **"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}